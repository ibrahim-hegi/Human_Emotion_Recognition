{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d28f79d-ca1c-4264-8d1c-e97759699479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Human_Emotion_Recognition.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Human_Emotion_Recognition.py\n",
    "\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "import tempfile\n",
    "\n",
    "st.title(\"Human Recognition Application\")\n",
    "st.write(\"Upload an image or video\")\n",
    "\n",
    "option=st.selectbox('choose an image or video',(\"image\",\"video\"))\n",
    "                                                \n",
    "#def a func for human emotion recognition                                                \n",
    "def Analyze_Emotion(image_or_video):\n",
    "    try:\n",
    "        analysis=DeepFace.analyze(image_or_video,actions=['emotion'],enforce_detection=False)\n",
    "        return analysis[0]['emotion']\n",
    "    except ValueError as e:\n",
    "        st.write(f'Error :{e}')\n",
    "        return None\n",
    "\n",
    "#to analyze image\n",
    "if option == \"image\":\n",
    "    upload=st.file_uploader(\"please Upload an image\",type=['png','jpg','jpeg'])\n",
    "    if upload is not None:\n",
    "        img=Image.open(upload)\n",
    "        img_array=np.array(img)\n",
    "        st.image(img_array,caption='Upload Image',channels='RGB',use_column_width=True)\n",
    "        emotion_scores= Analyze_Emotion(img_array)\n",
    "        if emotion_scores:\n",
    "            detected_emotion=max(emotion_scores,key=emotion_scores.get)\n",
    "            st.write(f'detected_emotion = {detected_emotion}')\n",
    "        else:\n",
    "            st.write(\"NO Face Detected\")\n",
    "\n",
    "\n",
    "if option == \"video\":\n",
    "    upload=st.file_uploader(\"please Upload an video\",type=['mp4','mov','avi'])\n",
    "    if upload is not None:\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as temp_video:\n",
    "                temp_video.write(upload.read())\n",
    "                video_path=temp_video.name\n",
    "            video = cv2.VideoCapture(video_path)\n",
    "            frame_rate=30\n",
    "            frame_count=0\n",
    "            while video.isOpened():\n",
    "                ret,frame= video.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame_count +=1\n",
    "                if frame_count % frame_rate==0:\n",
    "                    frame_rgb=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "                    emotion_scores= Analyze_Emotion(frame_rgb)\n",
    "                    if emotion_scores:\n",
    "                        detected_emotion=max(emotion_scores ,key = emotion_scores.get)\n",
    "                        cv2.putText(frame,detected_emotion, (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                    else:\n",
    "                         detection_emotion='No Detected Face'\n",
    "                         cv2.putText(frame,detected_emotion, (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                    st.image(frame, channels ='BGR')\n",
    "            video.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f38c0a-d360-408d-901e-3e30971282b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
